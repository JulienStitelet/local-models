[project]
name = "local-models"
version = "0.1.0"
description = ""
authors = [
    { name = "JulienStitelet", email = "julien.stitelet@careerbuilder.com" },
]
readme = "README.md"
requires-python = ">=3.10,<3.11"
# dependencies = [
#     "llama-cpp-python @ git+https://github.com/abetlen/llama-cpp-python.git@main",
#     "fastapi (>=0.115.14,<0.116.0)",
#     "uvicorn (>=0.35.0,<0.36.0)",
#     "torch (>=2.4.0,<=2.7.0)",
#     "huggingface-hub (>=0.33.2,<0.34.0)",
#     "langchain-pydantic-minifier (>=1.0.1,<2.0.0)",
#     "langchain-core (>=0.3.67,<0.4.0)",
#     "langchain-openai (>=0.3.27,<0.4.0)",
#     "pandas (>=2.3.0,<3.0.0)",
#     "pyarrow (>=20.0.0,<21.0.0)",
# ]

[tool.poetry]
packages = [{ include = "local_models", from = "src" }]


[tool.poetry.group.dev.dependencies]
isort = "^6.0.1"
black = "^25.1.0"
pylint = "^3.3.7"


[tool.poetry.dependencies]
llama-cpp-python = { git = "https://github.com/abetlen/llama-cpp-python.git", rev = "main" }
pandas = "^2.3.0"
torch = ">=2.4.0,<=2.7.0"
pyarrow = "^20.0.0"
huggingface-hub = "^0.33.2"
langchain-pydantic-minifier = "^1.0.2"
langchain-core = "^0.3.67"
langchain-openai = "^0.3.27"
uvicorn = "^0.35.0"
datasets = "^3.6.0"

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"
